学习笔记

---
## 本周作业

### 第三节课作业实践
1. 使用 GCLogAnalysis.java 自己演练一遍串行/并行/CMS/G1的案例。 
   - 作业1: [访问地址](https://github.com/yzsever/JAVA-000/tree/main/Week_02/01-GCLogAnalysisTest)
2. 使用压测工具(wrk或sb)，演练gateway-server-0.0.1-SNAPSHOT.jar 示例。 
   - 作业2: [访问地址](https://github.com/yzsever/JAVA-000/tree/main/Week_02/02-gateway-serverTest)
3. (选做)如果自己本地有可以运行的项目，可以按照2的方式进行演练。

根据上述自己对于1和2的演示，写一段对于不同 GC 的总结，提交到 Github。
   - 不同GC的总结：[访问地址](https://github.com/yzsever/JAVA-000/tree/main/Week_02/03-SummaryOfDifferentGC)

### 第四节课作业实践
1. (可选)运行课上的例子，以及 Netty 的例子，分析相关现象。

2. 写一段代码，使用 HttpClient 或 OkHttp 访问 http://localhost:8801，代码提交到 Github。
   - 作业5: [访问地址](https://github.com/yzsever/JAVA-000/tree/main/Week_02/05-CodeAccessURL)
---

## 第三课 JVM 核心技术(三):调优分析与面试经验

### 垃圾收集器总结脑图

![垃圾收集器](https://github.com/yzsever/JAVA-000/blob/main/Week_02/02-Image/01-GC.jp2?raw=true)

---

## 第四课 NIO 模型与 Netty 入门

> 问题1:线程池为什么创建了40个线程？

服务器通信过程中，存在两种类型操作:
- CPU 计算/业务处理
- IO 操作与等待/网络、磁盘、数据库

典型应用类型
- CPU密集型
- IO密集型：
   - B/S服务器：读磁盘/访问数据库

线程增多了，管理成本就增高，上下文切换就变多了。

socket的现有几个问题
1. 单线程时，有大量的等待，导致CPU使用率不高
2. 多个线程处理问题，导致了线程之间的竞争
3. 再底层，socket操作比我们想象的要复杂，内容需要从用户空间复制到内核空间才能被socket使用

### 通信模型
通信模式
- 同步
- 异步

线程处理模式
- 阻塞
- 非阻塞

### 五种IO模型
基本上都是同步的。

### IO模型-01 
**阻塞IO、BIO**

- 线程的问题
- 用户态和内核态数据拷贝
导致性能和并发都不高

一般通过在while(true)循环中服务端会调用accept()方法等待接收客户端的连接的方式监听请求，请求一旦接收到一个连接请求，就可以建立通信套接字在这个通信套接字上进行读写操作，此时不能再接收其他客户端 连接请求，只能等待同当前连接的客户端的操作执行完成，不过可以通过多线程来支持多个客户端的连接。

### IO模型-02 
**非阻塞式IO**

和阻塞IO类比，内核会立即返回，返回后获得足够的CPU时间继续做其它的事情。

用户进程第一个阶段不是阻塞的, 需要不断的主动询问kernel数据好了没有; 第二个阶段依然总是阻塞的。

### IO模型-03
**IO 多路复用(IO multiplexing)，也称事件驱动 IO(event-driven IO)**

在单个线程里同时监控多个套接字，通过select或poll轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。

IO复用同非阻塞IO本质一样，不过利用了新的select系统调用，由内核来负责本来是请求进程该做的轮询操作。看似比非阻塞IO还多了一个系统调用开销，不过因为可以支持多路IO，才算提高了效率。

进程先是阻塞在select/poll上，再是阻塞在读操作的第二个阶段上。

select/poll的几大缺点:
1. 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 
2. 同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大
3. select支持的文件描述符数量太小了，默认是1024

epoll(Linux 2.5.44内核中引入,2.6内核正式引入,可被用于代替POSIX select和poll系统调用):
1. 内核与用户空间共享一块内存
2. 通过回调解决遍历问题
3. fd 没有限制，可以支撑10万连接

### IO模型 - 04(线程池->EDA->SEDA)
**信号驱动I/O**

信号驱动IO与BIO和NIO最大的区别就在于，在IO执行的数据准备阶段，不会阻塞用户进程。

当用户进程需要等待数据的时候，会向内核发送一个信号，告诉内核我要什么数据，然后用户进程就继续做别的事情去了，而当内核中的数据准备好之后，内核立马发给用户进程一个信号，说”数据准备好了，快来查收“，用户进程收到信号之后，立马调用recvfrom，去查收数据。

EDA：
线程导致吞吐量劣化的问题：Event Handler。可以解决吞吐量问题，但是无法解决延迟的问题

SEDA：分阶段的事件驱动架构。多级缓冲模型。 延迟提升一部分

### IO模型-05
**异步式IO**

异步IO真正实现了IO全流程的非阻塞。用户进程发出系统调用后立即返回，内核等待数据准备完成，然后将数据拷贝到用户进程缓冲区，然后发送信号告诉用户进程IO操作执行完毕 (与SIGIO相比，一个是发送信号告诉用户进程数据准备完毕，一个是IO执行完毕)。